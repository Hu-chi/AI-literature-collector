[{"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8462", "abstract": "The behavior of users in social networks is often observed to be affected by the actions of their friends. Bhawalkar et\u00a0al. (ICALP '12) introduced a formal\u00a0mathematical model for user engagement in social networks where each individual derives a benefit proportional to the number of its friends which are engaged.\u00a0Given a threshold degree k the equilibrium for this model is a maximal subgraph whose minimum degree is at least k. However the dropping out of individuals with\u00a0degrees\u00a0less than k might lead to a cascading effect of iterated withdrawals such that the size of equilibrium subgraph becomes very small. To overcome this some\u00a0special vertices called \"anchors\" are introduced: these vertices need not have large degree. Bhawalkar et al. considered the Anchored k-Core problem: Given a\u00a0graph G and integers b, k and p do there exist sets of vertices B, H such that B is a subset of H, size of B is at most b and size of H is at least p, and every vertex\u00a0v which is in H but not in B has degree at least k in the induced subgraph G[H]. They showed that the problem is NP-hard for all k greater equal 2, and gave some\u00a0inapproximability and fixed-parameter intractability results. In this paper we give improved hardness results\u00a0for this problem. In particular we show that the\u00a0Anchored k-Core problem is W[1]-hard parameterized by p, even\u00a0for k=3. This improves the result of Bhawalkar et al. \u00a0(who show W[2]-hardness parameterized by\u00a0b)\u00a0as our parameter is always bigger since p is greater equal than b. Then we answer a question of Bhawalkar et al. by\u00a0showing that the Anchored k-Core problem\u00a0remains NP-hard on planar graphs for all k greater equal 3, even if the maximum\u00a0degree of the graph is k+2. Finally we show that the problem is FPT on planar\u00a0graphs parameterized by b for all k greater equal 7.", "title": "Preventing Unraveling in Social Networks Gets Harder"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8468", "abstract": "Linked Data is based on the idea that information from different sources can flexibly be connected to enable novel applications that individual datasets do not support on their own. This hinges upon the existence of links between datasets that would otherwise be isolated. The most notable form, sameAs links, are intended to express that two identifiers are equivalent in all respects. Unfortunately, many existing ones do not reflect such genuine identity. This study provides a novel method to analyse this phenomenon, based on a thorough theoretical analysis, as well as a novel graph-based method to resolve such issues to some extent. Our experiments on a representative Web-scale set of sameAs links from the Web of Data show that our method can identify and remove hundreds of thousands of constraint violations.Linked Data is based on the idea that information from different sources can flexibly be connected to enable novel applications that individual datasets do not support on their own. This hinges upon the existence of links between datasets that would otherwise be isolated. The most notable form, sameAs links, are intended to express that two identifiers are equivalent in all respects. Unfortunately, many existing ones do not reflect such genuine identity. This study provides a novel method to analyse this phenomenon, based on a thorough theoretical analysis, as well as a novel graph-based method to resolve such issues to some extent. Our experiments on a representative Web-scale set of sameAs links from the Web of Data show that our method can identify and remove hundreds of thousands of constraint violations.", "title": "Not Quite the Same: Identity Constraints for the Web of Linked Data"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8453", "abstract": "We present a novel method for ranking query paraphrases for effective search in community question answering (cQA). The method uses query logs from Yahoo! Search and Yahoo! Answers for automatically extracting a corpus of paraphrases of queries and questions using the query-question click history. Elements of this corpus are automatically ranked according to recall and mean reciprocal rank, and then used for learning two independent learning to rank models (SVMRank), whereby a set of new query paraphrases can be scored according to recall and MRR. We perform several automatic evaluation procedures using cross-validation for analyzing the behavior of various aspects of our learned ranking functions, which show that our method is useful and effective for search in cQA.", "title": "Learning to Rank Effective Paraphrases from Query Logs for Community Question Answering"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8454", "abstract": "To obtain high PageRank score nodes, the original approach iteratively computes the Page-Rank score of each node until convergence by using the whole graph.  If the graph is large, this approach is infeasible due to its high computational cost.  The goal of this study is to find top-k Page\\-Rank score nodes efficiently for a given graph without sacrificing accuracy.  Our solution, F-Rank, is based on two ideas:  (1) It iteratively estimates lower/upper bounds of Page\\-Rank scores, and (2) It constructs subgraphs in each iteration by pruning unnecessary nodes and edges to identify top-k nodes.  Our theoretical analysis shows that F-Rank guarantees result exactness.  Experiments show that F-Rank finds top-k nodes much faster than the original approach.", "title": "Fast and Exact Top-k Algorithm for PageRank"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8457", "abstract": "The amount of videos available on the Web is growing explosively. While some videos are very interesting and receive high rating from viewers, many of them are less interesting or even boring. This paper conducts a pilot study on the understanding of human perception of video interestingness, and demonstrates a simple computational method to identify more interesting videos. To this end we first construct two datasets of Flickr and YouTube videos respectively. Human judgements of interestingness are collected and used as the ground-truth for training computational models. We evaluate several off-the-shelf visual and audio features that are potentially useful for predicting interestingness on both datasets. Results indicate that audio and visual features are equally important and the combination of both modalities shows very promising results.", "title": "Understanding and Predicting Interestingness of Videos"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8456", "abstract": "We present a clustered personal classifier method (CPC method) that jointly estimates a classifier and clusters of workers in order to address the learning from crowds problem.Crowdsourcing allows us to create a large but low-quality data set at very low cost.The learning from crowds problem is to learn a classifier from such a low-quality data set.From some observations, we notice that workers form clusters according to their abilities.Although such a fact was pointed out several times, no method has applied it to the learning from crowds problem.We propose a CPC method that utilizes the clusters of the workers to improve the performance of the obtained classifier, where both the classifier and the clusters of the workers are estimated.The proposed method has two advantages.One is that it realizes robust estimation of the classifier because it utilizes prior knowledge about the workers that they tend to form clusters.The other is that we can obtain the clusters of the workers, which help us analyze the properties of the workers.Experimental results on synthetic and real data sets indicate that the proposed method can estimate the classifier robustly.In addition, clustering workers is shown to work well. Especially in the real data set, an outlier worker was found by applying the proposed method.", "title": "Clustering Crowds"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8451", "abstract": "Probabilistic models can learn users' preferences from the history of their item adoptions on a social media site, and in turn, recommend new items to users based on learned preferences. However, current models ignore psychological factors that play an important role in shaping online social behavior. One such factor is attention, the mechanism that integrates perceptual and cognitive features to select the items the user will consciously process and may eventually adopt. Recent research has shown that people have finite attention, which constrains their online interactions, and that they divide their limited attention non-uniformly over other people. We propose a collaborative topic regression model that incorporates limited, non-uniformly divided attention. We show that the proposed model is able to learn more accurate user preferences than state-of-art models, which do not take human cognitive factors into account. Specifically we analyze voting on news items on the social news aggregator and show that our model is better able to predict held out votes than alternate models. Our study demonstrates that psycho-socially motivated models are better able to describe and predict observed behavior than models which only consider latent social structure and content.", "title": "LA-CTR: A Limited Attention Collaborative Topic Regression for Social Media"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8463", "abstract": "We study recommendation in scenarios where there's no prior information about the quality of content in the system. We present an online algorithm that continually optimizes recommendation relevance based on behavior of past users. Our method trades weaker theoretical guarantees in asymptotic performance than the state-of-the-art for stronger theoretical guarantees in the online setting. We test our algorithm on real-world data collected from previous recommender systems and show that our algorithm learns faster than existing methods and performs equally well in the long-run.", "title": "A Fast Bandit Algorithm for Recommendation to Users With Heterogenous Tastes"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8460", "abstract": "Designers of human computation systms often face the need to aggregate noisy information provided by multiple people. While voting is often used for this purpose, the choice of voting method is typically not principled. We conduct extensive experiments on Amazon Mechanical Turk to better understand how different voting rules perform in practice. Our empirical conclusions show that noisy human voting can differ from what popular theoretical models would predict. Our short-term goal is to motivate the design of better human computation systems; our long-term goal is to spark an interaction between researchers in (computational) social choice and human computation.", "title": "Better Human Computation Through Principled Voting"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8459", "abstract": "With the proliferation of its applications in various industries, sentiment analysis by using publicly available web data has become an active research area in text classification during these years. It is argued by researchers that semi-supervised learning is an effective approach to this problem since it is capable to mitigate the manual labeling effort which is usually expensive and time-consuming. However, there was a long-term debate on the effectiveness of unlabeled data in text classification. This was partially caused by the fact that many assumptions in theoretic analysis often do not hold in practice. We argue that this problem may be further understood by adding an additional dimension in the experiment. This allows us to address this problem in the perspective of bias and variance in a broader view. We show that the well-known performance degradation issue caused by unlabeled data can be reproduced as a subset of the whole scenario. We argue that if the bias-variance trade-off is to be better balanced by a more effective feature selection method unlabeled data is very likely to boost the classification performance. We then propose a feature selection framework in which labeled and unlabeled training samples are both considered. We discuss its potential in achieving such a balance. Besides, the application in financial sentiment analysis is chosen because it not only exemplifies an important application, the data possesses better illustrative power as well. The implications of this study in text classification and financial sentiment analysis are both discussed.", "title": "Exploring the Contribution of Unlabeled Data in Financial Sentiment Analysis"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8465", "abstract": "Object localization is an image annotation task which consists of finding the location of a target object in an image. It is common to crowdsource annotation tasks and aggregate responses to estimate the true annotation. While for other kinds of annotations consensus is simple and powerful, it cannot be applied to object localization as effectively due to the task's rich answer space and inherent noise in responses.    We propose a probabilistic graphical model to localize objects in images based on responses from the crowd.  We improve upon natural aggregation methods such as the mean and the median by simultaneously estimating the difficulty level of each question and skill level of every participant.    We empirically evaluate our model on crowdsourced data and show that our method outperforms simple aggregators both in estimating the true locations and in ranking participants by their ability. We also propose a simple adaptive sourcing scheme that works well for very sparse datasets.", "title": "Hotspotting \u2014 A Probabilistic Graphical Model For Image Object Localization Through Crowdsourcing"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8467", "abstract": "In this paper, we investigate information validation tasks that are initiated as queries from either automated agents or humans.  We introduce OpenEval, a new online information validation technique, which uses  information on the web to automatically evaluate the truth of queries that are stated as multi-argument predicate instances (e.g., DrugHasSideEffect(Aspirin,GI Bleeding)).  OpenEval gets a small number of instances of a predicate as seed positive examples and automatically learns how to evaluate the truth of a new predicate instance by querying the web and processing the retrieved unstructured web pages. We show that OpenEval is able to respond to the queries within a limited amount of time while also achieving high F1 score. In addition, we show that the accuracy of responses provided by OpenEval is increased as more time is given for evaluation.  We have extensively tested our model and shown empirical results that illustrate the effectiveness of our approach compared to related techniques.", "title": "OpenEval: Web Information Query Evaluation"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8455", "abstract": "In AI and Web communities, modularity-based graph clustering algorithms are being applied to various applications. However, existing algorithms are not applied to large graphs because they have to scan all vertices/edges iteratively. The goal of this paper is to efficiently compute clusters with high modularity from extremely large graphs with more than a few billion edges. The heart of our solution is to compute clusters by incrementally pruning unnecessary vertices/edges and optimizing the order of vertex selections. Our experiments show that our proposal outperforms all other modularity-based algorithms in terms of computation time, and it finds clusters with high modularity.", "title": "Fast Algorithm for Modularity-Based Graph Clustering"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8452", "abstract": "So-called combined approaches answer a conjunctive query over a description logic ontology in three steps: first, they materialise certain consequences of the ontology and the data; second, they evaluate the query over the data; and third, they filter the result of the second phase to eliminate unsound answers. Such approaches were developed for various members of the DL-Lite and the EL families of languages, but none of them can handle ontologies containing nominals. In our work, we bridge this gap and present a combined query answering approach for ELHO--a logic that contains all features of the OWL 2 EL standard apart from transitive roles and complex role inclusions. This extension is nontrivial because nominals require equality reasoning, which introduces complexity into the first and the third step. Our empirical evaluation suggests that our technique is suitable for practical application, and so it provides a practical basis for conjunctive query answering in a large fragment of OWL 2 EL.", "title": "Introducing Nominals to the Combined Query Answering Approaches for EL"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8466", "abstract": "In this paper we introduce the Target Oriented Network Intelligence Collection (TONIC) problem, which is the problem of finding profiles in a social network that contain information about a given target via automated crawling. We formalize TONIC as a search problem and a best-first approach is proposed for solving it.Several heuristics are presented to guide this search.These heuristics are based on the topology of the currently known part of the social network.The efficiency of the proposed heuristics and the effect of the graph topology on their performance is experimentally evaluated on the Google+ social network.", "title": "TONIC: Target Oriented Network Intelligence Collection for the Social Web"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8461", "abstract": "Online labor markets such as Amazon Mechanical Turk (MTurk) have emerged as platforms that facilitate the allocation of productive effort across global economies. Many of these markets compensate workers with monetary payments. We study the effects of performance-contingent financial rewards on work quality and worker effort in MTurk via two experiments. We find that the magnitude of performance-contingent financial rewards alone affects neither quality nor effort. However, when workers working on two tasks of the same type in a sequence, the change in the magnitude of the reward over the two tasks affects both. In particular, both work quality and worker effort increase (alternatively decrease) as the reward increases (alternatively decreases) for the second task. This suggests the existence of the anchoring effect on workers\u2019 perception of incentives in MTurk and that this effect can be leveraged in workflow design to increase the effectiveness of financial incentives.", "title": "The Effects of Performance-Contingent Financial Incentives in Online Labor Markets"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8464", "abstract": "As the major component of big data, unstructured heterogeneous multimedia content such as text, image, audio, video and 3D increasing rapidly on the Internet. User demand a new type of cross-media retrieval where user can search results across various media by submitting query of any media. Since the query and the retrieved results can be of different media, how to learn a heterogeneous metric is the key challenge. Most existing metric learning algorithms only focus on a single media where all of the media objects share the same data representation. In this paper, we propose a joint graph regularized heterogeneous metric learning (JGRHML) algorithm, which integrates the structure of different media into a joint graph regularization. In JGRHML, different media are complementary to each other and optimizing them simultaneously can make the solution smoother for both media and further improve the accuracy of the final metric. Based on the heterogeneous metric, we further learn a high-level semantic metric through label propagation. JGRHML is effective to explore the semantic relationship hidden across different modalities. The experimental results on two datasets with up to five media types show the effectiveness of our proposed approach.", "title": "Heterogeneous Metric Learning with Joint Graph Regularization for Cross-Media Retrieval"}, {"url": "https://ojs.aaai.org/index.php/AAAI/article/view/8458", "abstract": "Recommender systems, especially the newly launched ones, have to deal with the data-sparsity issue, where little existing rating information is available. Recently, transfer learning has been proposed to address this problem by leveraging the knowledge from related recommender systems where rich collaborative data are available. However, most previous transfer learning models assume that entity-correspondences across different systems are given as input, which means that for any entity (e.g., a user or an item) in a target system, its corresponding entity in a source system is known. This assumption can hardly be satisfied in real-world scenarios where entity-correspondences across systems are usually unknown, and the cost of identifying them can be expensive.  For example, it is extremely difficult to identify whether a user A from Facebook and a user B from Twitter are the same person. In this paper, we propose a framework to construct entity correspondence with limited budget by using active learning to facilitate knowledge transfer across recommender systems. Specifically, for the purpose of maximizing knowledge transfer, we first iteratively select entities in the target system based on our proposed criterion to query their correspondences in the source system. We then plug the actively constructed entity-correspondence mapping into a general transferred collaborative-filtering model to improve recommendation quality. We perform extensive experiments on real world datasets to verify the effectiveness of our proposed framework for this cross-system recommendation problem.", "title": "Active Transfer Learning for Cross-System Recommendation"}]